# 课设 俄罗斯方块 概要设计

## OJ 版 需求、思路分析

### 概论

我们现在需要实现一个输入即将到来的两个方块，给出接下来一步的最优策略，同时在内部维护整个俄罗斯方块游戏状态，输出每一步的得分和最优策略的交互程序。

给出两个方块，其合法策略的数量是有限的。对于每个方块，遍历其所有可能旋转方向（最多 4 种）和其所有横坐标（最多 9 种），再减去不合法的放置方式（例如超出边界、旋转方向重复）等，就是所有的策略。可见最多有 $(4\times9)^2=1296$ 种的情况，我们的计算开销有些大。实际上，如果我们只遍历一个方块的旋转情况，就可以通过 OJ 的 10 万块测试；但如果需要冲击一百万块，则需要遍历两个方块。

然后，我们便可以通过一个评估函数 $V(status) = score$ 来给出每个策略的评分（后续通过进一步了解我知道了这叫*启发式评估函数* *Heuristic Evaluation Function*），取评分最高的策略，也就是我们的最优策略了。每一步都进行评估，执行最优策略，我们就能最终得到一个比较高的游戏分数。

### 思路分析

核心思路可分为以下几个步骤：

1. 状态表示：精确地用数据结构描述游戏世界的一切元素，包括游戏区域、方块的各种形态、一个具体的放置动作以及整体游戏状态。
2. 动作生成：对于当前下落的方块，遍历其所有可能的旋转形态和所有可能的水平位置，生成一个“所有合法动作”的集合。
3. 状态评估：设计一个评估函数 $V(S)$，该函数可以量化一个游戏局面 $S$ 的“好坏程度”。一个好的局面通常具有较少的空洞、平整的表面等特征。
4. 策略选择：
   * 单步预测：仅考虑当前下落的方块。遍历所有合法动作，模拟执行每个动作后形成的新局面，使用评估函数 $V(S')$ 对新局面进行打分，选择得分最高的动作。
   * 两步预测：同时考虑当前和下一个方块。遍历当前方块的所有合法动作 $A_1$，在每个动作形成的新局面上，再遍历下一个方块的所有合法动作 $A_2$。评估执行 $A_1$ 和 $A_2$ 后的最终局面，选择能使最终局面最优的 $A_1$ 作为当前步骤的决策。这种方式计算量大，但通常决策更优。
5. 主循环：将以上步骤整合进一个游戏主循环中。每一步，程序接收新的方块信息，执行决策，更新游戏状态（包括分数和游戏区域），并输出选择的动作。

### 核心数据结构

1. 基础几何结构

```c
typedef struct { int width; int height; } Size; // 描述尺寸
typedef struct { int x; int y; } Pos;           // 描述二维坐标
```

2. 方块定义：为了提升性能并简化逻辑，所有7种方块（I, T, O, J, L, S, Z）及其所有旋转形态（最多4种）都被预先定义为常量。这种以空间换时间的设计避免了运行时进行复杂的旋转计算。

```c
// 描述方块的一种旋转形态
typedef struct {
    int label;             // 旋转角度 (0, 90, 180, 270)
    Size size;             // 该形态的尺寸
    Pos* occupied;         // 组成方块的各单元格的相对坐标
    int occupied_count;    // 单元格数量 (固定为4)
} BlockRotation;

// 描述一种方块类型
typedef struct {
    char name;                 // 方块名称 ('I', 'T', ...)
    BlockRotation* rotations;  // 所有旋转形态的数组
    int rotations_count;       // 旋转形态的数量（实际上均为 4）
} Block;
```

下面是一个方块类型 I 的枚举常量的例子。其中，我个人偏好的代码风格（参考 Google C++ Style）是在常量前面加上 `k_` 前缀（`k` 代表 `const`），而非全部大写：

```c
const Block k_block_I = {
    .name = 'I',
    .rotations = (BlockRotation[]) {
        { .label = 0,
            .size = { 1, 4 },
            .occupied = (Pos[]) { { 0, 0 }, { 0, 1 }, { 0, 2 }, { 0, 3 } },
            .occupied_count = 4 },
        { .label = 90,
            .size = { 4, 1 },
            .occupied = (Pos[]) { { 0, 0 }, { 1, 0 }, { 2, 0 }, { 3, 0 } },
            .occupied_count = 4 } },
    .rotations_count = 2
};

const *Block const k_blocks[] = {
    &k_block_I,
    // 其他方块类型...
};
```

3. 动作与评估
   
   - `BlockStatus` 代表一个具体的、可执行的放置动作。

```c
// 描述一个完整的放置动作/策略
typedef struct {
    int x_offset;          // 放置后的水平偏移量
    BlockRotation* rotation; // 采用的旋转形态
    int y_offset;          // 放置后的垂直偏移量 (需计算得出)
    double assement_score; // 该动作的评估分数 (需计算得出)
} BlockStatus;
```

- 游戏核心状态：`Board`, `GameConfig`, `Game`, `Context` 等结构体共同构成了完整的游戏逻辑。

```c
// 描述游戏区域
typedef struct {
    Size size;             // 逻辑尺寸 (如 10x16)
    short** grid;          // 网格。1为占用, 0为空。为处理超出顶部的方块，实际分配的高度会大于逻辑高度，形成一个缓冲区。
} Board;

// 游戏基础配置
typedef struct {
    int* awards;           // 消除1-4行时的得分奖励
    Block* available_blocks; // 指向所有方块定义的常量数组
    int available_blocks_count;
} GameConfig;

// 描述完整的游戏状态
typedef struct {
    GameConfig config;
    Board board;           // 当前游戏区域状态
    long score;            // 当前分数。设计为负数时代表游戏结束。

    Block** upcoming_blocks; // 待处理的方块队列 (大小为2)
    // 为支持两步预测，分别存储两步的所有可能动作
    BlockStatus** available_statuses_1; // 第一个方块的所有可能动作
    int available_statuses_1_count;
    BlockStatus** available_statuses_2; // 第二个方块的所有可能动作
    int available_statuses_2_count;
} Game;

// 评估模型，封装了评估函数的权重
typedef struct {
    int length;            // 特征数量
    double* weights;       // 权重数组，包含一个常数项
} AssessmentModel;

// 上下文，方便在函数间传递游戏核心对象
typedef struct {
    Game* game;
    AssessmentModel* model;
} Context;
```

### 核心功能函数

#### 游戏逻辑、状态更新

这类函数负责实现俄罗斯方块的基本规则。

- `int findYOffset(const Board* board, BlockStatus* action)`: 这是计算方块最终落点的核心函数。它从棋盘顶部（y=0）开始向下逐行试探，直到找到第一个不会与现有方块发生碰撞的位置。如果方块一出现就发生碰撞（即游戏结束），则返回 `-1`。
- `IntList* getFullLines(const Board* board)`: 遍历游戏区域的每一行，使用 `isLineFull` 检查该行是否被完全填满，并返回所有满行的行号列表。
- `size_t clearFullLines(Board* board, IntList* full_lines)`: 根据 `getFullLines` 的结果，从游戏区域中移除满行，并将上方的方块整体下移。它通过一个读写双指针的逻辑高效地完成下移操作，避免了逐行复制。
- `int executeAction(Game* game, BlockStatus* action, int eliminate)`: **（产生副作用）** 该函数将一个确定的 `action` 应用到主游戏 `game` 的 `board` 上。该函数会进行下面的操作：
  1. 计算并确定最终的 `y_offset`。
  2. 将方块实体放置到 `board->grid` 中。
  3. 调用 `getFullLines` 和 `clearFullLines` 处理消行。
  4. 根据消行数量更新 `game->score`。
  5. 检查游戏是否结束（方块是否超出顶部缓冲区）。

#### 决策、模拟

这类函数是AI决策的基础，负责“思考”和“预判”。

- `BlockStatus** getAvailableActions(Game* game, Block* block)`: 为给定的 `block` 生成所有可能的放置策略。它遍历该 `block` 的所有 `rotations` 和所有合法的 `x_offset`，为每个组合创建一个 `BlockStatus` 对象，并调用 `findYOffset` 预计算落点。同时会进行判断，不返回无效的动作（如会立刻导致游戏结束的）。
- `void extractFeatures(...)`: **（无副作用的模拟）** 这是进行局面评估前的关键函数。它**不会修改**传入的 `board`。其流程是：
  1. 创建一个 `board` 的**临时副本**。
  2. 在副本上模拟执行指定的 `action`。
  3. 在副本上模拟消行。
  4. 计算并提取新局面的所有特征参数（如空洞数、行变换等）。
  5. 返回计算出的特征向量

### AI 评估与决策算法

#### 评估函数

为了量化一个局面的优劣，我们采用一个线性评估函数：

$V(S) = \sum_{i=1}^{n} w_i \cdot f_i(S) + w_{n+1}$

 其中，$S$ 是一个游戏局面，$f_i(S)$ 是该局面的第 $i$ 个特征值，$w_i$ 是对应的权重。

#### 特征工程

查阅不同文献，发现目前主流、得分较高的特征参数组是综合了 Dellacherie + Bertsekas + Christophe Thiery, Bruno Scherrer 的研究成果的一组特征参数。下面遵循原文称之为 BDU 特征参数。

BDU 特征参数内容如下表，我们编写了不同的函数来获取这些参数。

| 特征 (Feature)          | 对应函数/逻辑                 | 说明                                    |
| --------------------- | ----------------------- | ------------------------------------- |
| 1. Landing Height     | `action->y_offset`      | 方块落点的高度。通常希望方块落在较低位置。                 |
| 2. Eroded Piece Cells | `calcErodedPieceCells`  | *(消除的行数)* × *(当前方块在这些行中的格子数)*。鼓励高效消行。 |
| 3. Row Transitions    | `calcRowTransitions`    | 水平方向空格与实格的交错次数。值越小，表面越平整。             |
| 4. Column Transitions | `calcColumnTransitions` | 垂直方向空格与实格的交错次数。值越小，垂直结构越连续。           |
| 5. Number of Holes    | `calcHolesAndDepth`     | 被方块覆盖的空格总数。空洞是局面的主要负面因素。              |
| 6. Board Wells        | `calcBoardWells`        | 井（两侧或一侧和边界被占据的空格列）的深度加权和。             |
| 7. Total Hole Depth   | `calcHolesAndDepth`     | 所有空洞上方覆盖的方块层数之和。惩罚深层空洞。               |
| 8. Rows with Holes    | `calcHolesAndDepth`     | 存在空洞的行数。                              |

#### 训练权重参数 $w_i$

采用交叉熵方法（**C**ross-**E**ntropy **M**ethod, CEM）进行训练。该方法较为简单，求解费时短，在简单的情况下较为有效。

该方法的核心思想是，通过随机初始参数，验证参数的效果，然后再抽取前一部分效果好的参数，继续调整分布的参数，不断循环取出效果较好的参数，一步步迭代进行优化，更新参数分布（均值和标准差），逐步逼近最佳的参数。

所以，我们首先根据原文献中给的值，从一个较好的参数向量开始。

```cpp
 std::vector<double> initial_good_params = {
     -12.63, 6.60, -9.22, -19.77, -13.08, -10.49, -1.61, -24.04, 0.0
 };
```

进行初始化，准备开始我们的迭代训练。

```cpp
auto mu = initial_good_params;
std::vector<double> sigma(k_num_params, k_inital_std_dev);
// 参数个数：9，初始标准差：5.0
```

进行 50 次迭代，每次的流程如下：

1. 从当前的参数分布（由均值 `mu` 和标准差 `sigma` 定义的正态分布）中随机抽取 `k_population_size` 组参数。

```cpp
// 采样
std::vector<std::vector<double>> population_params(k_population_size, std::vector<double>(k_num_params));
for (int i = 0; i < k_population_size; ++i) {
    for (int j = 0; j < k_num_params; ++j) {
        std::normal_distribution<double> dist(mu[j], sigma[j]);
        population_params[i][j] = dist(main_rng);
    }
}
```

2. 使用多个线程评估上一步中的每一组参数向量。对于每组参数，运行 `k_num_games_per_eval` 次游戏，计算平均得分作为其指标。

```cpp
// 运行游戏的工具函数：
struct EvalResult {    // 保存 evaluate_parameters() 结果
    int index;
    double average_score;
};

// 通过运行多个游戏来评估单组参数。index 用于记录日志，但此处略去相关代码
EvalResult evaluate_parameters(int index, const std::vector<double>& params)
{
    double total_score = 0;

    for (int i = 0; i < k_num_games_per_eval; ++i) {        
        int score = runGameForTraining(params);  // 需要我去实现这个函数，接收一组参数向量，返回游戏得分
        total_score += score;
    }

    double avg_score = (k_num_games_per_eval > 0) ? (total_score / k_num_games_per_eval) : 0.0;
    return { index, avg_score };
}

// CEM 训练主循环内：
std::vector<std::future<EvalResult>> futures;
futures.reserve(k_population_size);

// 启动异步任务
for (int i = 0; i < k_population_size; ++i) {
    futures.push_back(std::async(std::launch::async, evaluate_parameters, i, population_params[i]));
}

// 等待所有并行任务完成，储存平均得分
std::vector<EvalResult> results;
results.reserve(k_population_size);
int completed_count = 0;
for (auto& fut : futures) {
    results.push_back(fut.get()); // 阻塞直到 future 就绪
}

// 将评估结果按照平均得分从高到低排序，找到表现最好的一组参数
std::sort(results.begin(), results.end(), [](const EvalResult& a, const EvalResult& b) {
    return a.average_score > b.average_score; 
});
```

3. 选择精英

从排序后的结果中选择得分最高的 top `k_elite_frac` 百分比的参数组作为“精英”，代表本次迭代中，表现最好的参数向量。

```cpp
int num_elites = static_cast<int>(k_population_size * k_elite_frac);
if (num_elites == 0 && k_population_size > 0)
    num_elites = 1; // 确保至少有一个精英

std::vector<std::vector<double>> elite_params;
elite_params.reserve(num_elites);
for (int i = 0; i < num_elites && i < results.size(); ++i) {
    elite_params.push_back(population_params[results[i].index]);
}
```

4. 更新分布

使用选出的精英参数组来更新下一次迭代的参数分布。将新的均值 `mu`)设定为精英参数向量各参数的平均值，新的标准差 `sigma` 设为精英参数各维度的标准差（加上一个小的 `epsilon` 防止其变为零）。

```cpp
std::vector<double> next_mu(k_num_params, 0.0);
std::vector<double> next_sigma(k_num_params, 0.0);

// 计算新的 mu
for (int j = 0; j < k_num_params; ++j) {
    double sum = 0.0;
    std::vector<double> param_values_j;
    param_values_j.reserve(elite_params.size());
    for (const auto& elite : elite_params) {
        param_values_j.push_back(elite[j]);
    }
    next_mu[j] = calculateMean(param_values_j);
}

// 计算新的 sigma
for (int j = 0; j < k_num_params; ++j) {
    std::vector<double> param_values_j;
    param_values_j.reserve(elite_params.size());
    for (const auto& elite : elite_params) {
        param_values_j.push_back(elite[j]);
    }
    next_sigma[j] = calculateStdDev(param_values_j, next_mu[j]) + k_std_dev_epsilon; // 添加 epsilon
}

mu = next_mu;
sigma = next_sigma;
```

经过 50 次迭代后，训练结束，就可以把训练出来的最佳参数，也就是迭代完后的 `mu` 硬编码到 OJ 版程序的 `AssessmentModel` 结构体的 `weights` 中，便可以用这组最佳参数向量进行游戏模拟了。

#### 决策算法

程序实现了多种决策模式，通过 `mode` 参数在 `runGameStep` 函数中进行切换，我在提交不同的版本中进行了手动修改。

1. **模式1：单步最优**
   
   - 调用 `findBestSingleAction` 函数。
   - 该函数遍历当前方块的所有合法动作。
   - 对每个动作，使用 `extractFeatures` 模拟执行并获取特征，然后用 `caculateLinearFunction` 计算得分。
   - 返回得分最高的那个动作。
   - **优点**：计算速度快。**缺点**：目光短浅，可能会为了当前一步的小利而造成未来的困局。

2. **模式2：两步最优**
   
   - 调用 `findBestAction` 函数。
   - 该函数使用一个嵌套循环：外层遍历第一个方块的所有动作 `action1`，内层遍历第二个方块的所有动作 `action2`。
   - 对于每一对 `(action1, action2)`，调用 `assessmentTwoActions` 函数。此函数会：
     a. 模拟执行 `action1` 得到中间局面 `board1`。
     b. 在 `board1` 上模拟执行 `action2` 得到最终局面 `board2`。
     c. 评估 `board1` 和 `board2`，将两者的评估分数相加作为这对动作序列的总分。
   - 选择总分最高的 `(action1, action2)` 组合，并返回 `action1` 作为当前步骤的决策。
   - **优点**：具有更强的预判能力，决策质量更高，适合于 100 万块测验。**缺点**：计算量呈平方级增长，非常耗时。

3. **模式3：剪枝优化的两步最优**
   
   - 调用 `findBestActionV3` 函数。
   - 这是对模式2的优化，采用了一种束搜索的思想进行剪枝。
   - 步骤：
     a. 首先，像模式1一样，计算出第一个方块所有动作的单步得分。
     b. 对这些动作按得分进行排序，只保留得分最高的 *Top N*%（本程序为 10%）的动作作为候选集。
     c. 然后，只在这些精英候选动作的基础上，进行模式2的嵌套搜索。
   - **优点**：在决策质量和计算效率之间取得了很好的平衡，是冲击高分的主要策略。

### 主循环流程

main` 函数是程序的入口，负责初始化和驱动整个游戏循环。

1. 初始化
   - 创建并初始化 `Game` 结构体，包括设置游戏区域大小、分配 `grid` 内存。
   - 初始化 `AssessmentModel`，载入预训练的权重。
   - 将 `Game` 和 `AssessmentModel` 封装到 `Context` 结构体中。
2. 模式选择
   - 通过命令行参数（如 `single`, `double`）或编译宏（`DEBUG_MODE`）来决定运行模式。
   - 测试模式 (`runRandomTest`): 在此模式下，程序会随机生成方块序列，自动运行游戏直到结束，用于调试算法和性能测试。
   - OJ模式: 遵循 OJ 系统的输入输出格式。
3. OJ模式主循环
   - 从标准输入或文件读取最初的两个方块。
   - 调用 `runGameStep` 函数处理第一步。
   - 进入循环，每次从输入读取一个新方块。
   - 调用 `runGameStep`，传入新的方块信息，该函数会：
     a. 更新 `game->upcoming_blocks` 队列。
     b. 调用 `getAvailableActions` 为新局面生成动作集。
     c. 根据设定的 `mode` 调用对应的 `findBestAction...` 函数进行决策。
     d. 调用 `executeAction` 应用最优决策，更新游戏状态。
     e. 返回执行的动作信息。
   - 根据 `runGameStep` 的返回结果，向标准输出打印决策（旋转和位置）和当前分数。
   - 循环直到游戏结束或收到 `E` 或 `X` 的结束信号。
4. 资源释放
   - 在程序结束前，调用 `GridFree` 和 `freeActionsArray` 等函数，释放所有动态分配的内存，避免内存泄漏。

# 实验心得与总结

这次俄罗斯方块课设对我而言是一次 C/C++ 语言编程能力的综合测验，让我收获颇丰，让我走了一遍从需求分析、系统设计、算法实现到性能优化的全方位实战演练。

#### 团队协作（图形化版本）

在看到项目要求时，我本来是想着一个人完成的，我心中存在许多顾虑，担心与组员在技术栈或工作习惯上磨合不畅，怕产生冲突影响进度........这种对未知和潜在摩擦的担忧，甚至一度让我觉得小组合作比写代码本身还要“可怕”。

不过根据要求，我还是找到了两名组员进行协作开发。我花了不少心思进行前期调研，包括环境配置、简单的 Git 使用、代码风格要求等，然后写到了云文档里，想尽量消除所有可能踩的坑，让大家能够心无旁骛地专注于代码本身→[云文档：项目开发简要指引](https://byr-team.feishu.cn/wiki/TfAzwEvjoioKZEki3Q9c7dCnnmh)

索性组员都十分给力，阅读了我给的文档并表示理解。鉴于组员并不太了解 Qt 和现代 C++ 的用法，我揽下来了和 Qt API 强相关的活，和设计项目总体架构的责任。我在搭建完整体的框架（参见[此版本](http://10.3.255.244/2024211016/tetris/-/tree/ec0d1fd59681b03609acdfe895466835c9fb5c2f)），画了下框架图，基本实现了我的部分（渲染游戏窗口）之后拉了个会议。会议上我不仅阐述了项目结构和分工，还耐心讲解了各个模块之间的接口和数据流，确保大家对全局有清晰的认知，然后让组员去开发自己负责的部分。在后续开发中，组员们认真阅读了文档，严格遵循了既定的框架和文档规范，选择自己最擅长的部分进行开发，这极大地减轻了我的协调负担，基本不太需要额外的担忧。

更让我感动的是，他们会主动同步进度，遇到问题时也会及时提出，而不是默默地“钻牛角尖”。整个团队就像一台高效运转的机器，每一个齿轮都咬合得恰到好处。我并没有把“问题”简单地推给他们，而是尽量主动靠前，帮助他们理解并解决问题。每一次代码提交的顺畅，每一次难题被攻克后大家共同的喜悦，都让我真切感受到 1+1+1>3 的团队力量。我甚至发现，指导和帮助组员本身就是一件充满成就感的事情，这种互动让整个开发过程变得更加生动有趣。

这次宝贵的团队合作经历让我深刻认识到：**合作不仅依赖于技术能力，更在于有效的沟通、清晰的规划和成员间的相互信任。只要项目负责人能够制定清晰明确的指导文档，有效沟通并传达项目要求，团队成员具备积极的合作意愿和执行力，就能克服原先想象中的团队合作的困难与阻碍。更重要的是，敞开心扉去交流，去支持彼此，那么，那些曾经以为“可怕”的挑战，最终都会化为我们共同闪耀的记忆。** 这次的合作不仅提升了我的项目管理和架构能力，也改变了我对团队协作的固有看法，让我知道了有效沟通的重要作用，更让我收获了远超代码本身的宝贵经验。

#### 理论到实践

在课堂上，我们学习了C语言的语法、指针、结构体和内存管理。但只有在这样一个具有一定复杂度的项目中，我才真正深刻体会到这些知识如何协同工作，构建出一个有机的整体。例如，如何巧妙地使用结构体（如 `Game`, `Board`, `BlockStatus`）来封装和管理复杂的游戏状态，如何通过指针在函数间高效传递数据，以及如何谨慎地使用 `malloc` 和 `free` 来管理动态内存，避免内存泄漏，这些都让我对C语言的理解从“知道”深化到了“会用”和“用好”。

#### 设计先行

项目初期，我曾想过直接上手编码。但面对俄罗斯方块这样一个状态多变、逻辑交错的游戏，我很快意识到“磨刀不误砍柴工”的道理。于是，我花费了大量时间进行概要设计，特别是对核心数据结构的定义，然而在实现的过程中，我还是进行了很多的修改与重构。一个清晰、合理的数据结构设计是项目成功的基石。

我将整个系统划分为几个清晰的模块：核心数据结构定义、游戏逻辑实现（如 `executeAction`, `clearFullLines`）、AI决策核心（如 `extractFeatures`, `findBestAction`）以及主控与交互。每个模块都有明确的职责边界。例如，`extractFeatures` 函数只负责“无副作用”的模拟和计算，它接收一个局面，返回一组特征值，而不改变任何全局状态。这种设计使得函数的功能变得单一和纯粹，极大地降低了调试的复杂性，也提高了代码的可复用性。当AI决策出现问题时，我可以很自信地将排查范围缩小到评估和决策模块，而不用担心是游戏逻辑部分出了错。这种“高内聚、低耦合”的设计思想，是我在本次项目中获得的最宝贵的工程经验之一。

#### 手动管理内存

在 Linux 系统第一次启动 `sudo` 时，会看到一句话“能力越大，责任越大”。我觉得手动管理内存，和 `sudo` 一样，都是一种责任与自由的博弈。

习惯了使用提供自动垃圾回收机制，和提供丰富面向对象抽象的高级语言，这次用 C 语言进行开发，我必须直面手动内存管理的挑战。从为棋盘 `grid` 分配二维数组，到为每一个可能的 `BlockStatus` 动作动态创建空间，再到每一步 AI 决策结束和游戏结束后细心释放所有资源，每一步都要求我保持清晰的头脑，明确每一块内存的“所有权”和“生命周期”。

这个过程让我对程序的底层运行机制有了更深刻的理解。我学会了如何使用 `malloc` 精准地申请所需内存，我养成了在 `free` 之前进行非空判断、在释放后将指针置为 `NULL` 的良好习惯，以防止悬空指针和重复释放等棘手问题。

我觉得，虽然手动管理内存增加了心智负担，但它也赋予了程序员极致的控制力和性能优化的空间。这次“被逼无奈”的亲密接触，让我不再畏惧指针和内存操作，反而让我更加敬畏和珍视这份 C 语言赋予的自由与责任。

#### 站在巨人的肩膀上

“一个好的AI，其背后一定有坚实的理论支撑。”这是我在项目探索阶段得到的启示。最初，我对于如何评估一个局面的“好坏”感到非常迷茫，仅凭直觉想出的一两个特征效果并不理想，这促使我第一次主动去查阅相关的学术文献。

通过阅读前人的研究，我了解到了经典的 Dellacherie 特征集以及后来者们的改进，这为我的特征工程指明了清晰的方向。我学到了如何将一个模糊的“好局面”概念，分解为一系列可量化的、具体的指标。然后，我再针对每一个指标去设计和实现相应的计算函数。这个过程让我学会了如何站在巨人的肩膀上，将一个宏大而复杂的问题（“如何玩好俄罗斯方块？”），层层分解为一个个独立的、可解决的子问题。、

#### 调试的艺术

在开发过程中，最令人头疼的就是调试，尤其是在处理棋盘状态这种复杂数据时，屏幕上输出的错误结果和调试器中显示的变量，往往无法直接定位问题根源。为此，我编写了 `visualizeStep` 函数，它能将内存中抽象的 `board->grid` 二维数组以字符画的形式打印到控制台，让我能“看见”每一步操作后棋盘的真实状态，许多关于边界判断、坐标计算和消行逻辑的bug都在它的帮助下迎刃而解。

同时因为缺乏手动管理的经验，我还多次使用了 Clang 提供的 ASAN 工具，跑了多次测试获取日志，然后交给 AI 分析，才发现了各种多次释放和悬空指针的问题。

我体会到，优秀的程序员不仅要会写代码，更要会使用和创造工具来帮助自己理解和调试代码。

#### 性能优化

为了在 OJ 平台上取得更高的分数，程序的运行效率至关重要。最初的“两步预测”算法虽然决策质量高，但其 $O(N^2)$ 的复杂度让程序在后期运行缓慢。这促使我思考如何进行优化。最终实现的 `findBestActionV3` 函数，通过“*Top N*%剪枝”的策略，在保证决策质量基本不受影响的前提下，大幅削减了计算量。这个优化过程让我学到了在算法设计中，必须在“效果”和“效率”之间做出权衡与取舍，寻找那个精妙的平衡点。

查看统计数据，我总共在 OJ 版项目上花费了 87h，包括一部分训练的时间；图形化版花费 33.5h。由于训练代码是 C++ 编写，我也学到了很多 C++ 相关的特性知识，熟悉了 CMake 等工具链的使用。训练参数的黑箱过程是痛苦而乏味的，总是需要思考哪里有小问题，哪些地方可以优化，并花费大量的时间等待。

总之，这次课程设计是一次宝贵的学习经历，它不仅锻炼了我的C语言编程能力，更提升了我的工程思维、算法设计和问题解决能力。我学会了如何将一个复杂问题分解为多个可管理的模块，如何设计数据结构来服务于算法，以及如何通过有效的工具和策略来调试和优化程序。
